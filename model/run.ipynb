{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.dataset import random_split\n",
    "from datetime import *\n",
    "from sklearn.model_selection import KFold \n",
    "from torchmetrics import RetrievalMRR\n",
    "\n",
    "import load_data\n",
    "import utils\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147729\n",
      "5130 5140\n",
      "208 210\n",
      "1083 50\n"
     ]
    }
   ],
   "source": [
    "dname='nyc'\n",
    "filter_data=pd.read_csv('../data/'+dname+'_filter_data.csv')\n",
    "seq_data_path='../data/'+dname+'_seq_data_pad'\n",
    "\n",
    "print(len(filter_data))\n",
    "poiNum=len(filter_data.groupby('venueid'))\n",
    "catNum=len(filter_data.groupby('categid'))\n",
    "userNum=len(filter_data.groupby('userid'))\n",
    "\n",
    "#用來pad序列資料中POI、類別編號和時間的數字，整數比較好看\n",
    "poiPad=((poiNum//10)+1)*10\n",
    "catPad=((catNum//10)+1)*10\n",
    "timePad=((48//10)+1)*10\n",
    "print(poiNum,poiPad)\n",
    "print(catNum,catPad)\n",
    "print(userNum,timePad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data length: 15992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15992/15992 [00:00<00:00, 55631.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([2815, 1211, 3602, 1502,  383, 2870, 5140, 5140, 5140, 5140, 5140, 5140,\n",
      "        5140, 5140]), tensor([  4,  36, 105, 108,  36,  48, 210, 210, 210, 210, 210, 210, 210, 210]), tensor([19, 22,  1, 24, 40, 42, 50, 50, 50, 50, 50, 50, 50, 50]), 1, 1508, 36, 48)\n",
      "Total:  15992\n",
      "Training Set:  12793\n",
      "Validation Set:  3199\n",
      "train batch: 400\n",
      "validation batch: 100\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size=32\n",
    "dataset=load_data.myDataset(seq_data_path, poiPad, catPad, timePad)\n",
    "first_data = dataset[1]\n",
    "print(first_data)\n",
    "\n",
    "# Split training and validation set\n",
    "train_len = int(0.8*len(dataset))\n",
    "valid_len = len(dataset) - train_len\n",
    "TrainData, ValidationData = random_split(dataset,[train_len, valid_len])\n",
    "\n",
    "# Load into Iterator (each time get one batch)\n",
    "train_loader = data.DataLoader(TrainData, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = data.DataLoader(ValidationData, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# Print statistics\n",
    "print(\"Total: \", len(dataset))\n",
    "print(\"Training Set: \", len(TrainData))\n",
    "print(\"Validation Set: \", len(ValidationData))\n",
    "print('train batch:',len(train_loader))\n",
    "print('validation batch:',len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1084, 208, 208)\n",
      "(5130, 5130)\n",
      "(1084, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "#A=np.load('../list/nyc_usercat_graph.npy')\n",
    "#C=np.load('../list/nyc_utc_graph.npy')\n",
    "A=np.load('../list/nyc_usercat_Norm.npy')\n",
    "C=np.load('../list/nyc_utc_Norm.npy')\n",
    "#A=np.load('../list/nyc_usercat_Percent.npy')\n",
    "#C=np.load('../list/nyc_utc_Percent.npy')\n",
    "B=np.load('../list/nyc_dis_graph.npy')\n",
    "\n",
    "for i in range(len(A)):\n",
    "    A[i]=utils.calculate_laplacian_matrix(A[i])\n",
    "print(A.shape)\n",
    "A = torch.from_numpy(A)\n",
    "A = A.to(device=device, dtype=torch.float)\n",
    "\n",
    "disGraph = utils.calculate_laplacian_matrix(B)\n",
    "print(disGraph.shape)\n",
    "disGraph = torch.from_numpy(disGraph)\n",
    "disGraph = disGraph.to(device=device, dtype=torch.float)\n",
    "\n",
    "for i in range(len(C)):\n",
    "    C[i]=utils.calculate_laplacian_matrix_time(C[i], catNum)\n",
    "print(C.shape)\n",
    "C = torch.from_numpy(C)\n",
    "C = C.to(device=device, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout=0.4\n",
    "DTTCG = model.DTTCG(poiPad, catPad, userNum).float().to(device)\n",
    "catGCN = model.batchGCN(dropout, catNum).to(device)\n",
    "timeGCN = model.batchGCN(dropout,catNum+48).to(device)\n",
    "disGCN = model.GCN(dropout, poiNum).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterionc = nn.CrossEntropyLoss()\n",
    "epochs=50\n",
    "optimizer = torch.optim.Adam(params=list(DTTCG.parameters()) +list(catGCN.parameters())\n",
    "                             +list(timeGCN.parameters())+list(disGCN.parameters()), lr=0.001)\n",
    "\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5,15,25,35,45], gamma=0.5)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #start training\n",
    "    DTTCG.train()     # Enter Train Mode\n",
    "    catGCN.train()\n",
    "    timeGCN.train()\n",
    "    disGCN.train()\n",
    "\n",
    "    correct,correctc = 0,0\n",
    "    loss_sum, num=0, len(train_loader.dataset) \n",
    "\n",
    "    for batch_id, batch in enumerate(train_loader):\n",
    "        p, c, t, u, targets, targetsc, lastc = [d.to(device) for d in batch]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        userGraph=A[u]\n",
    "        catNode=DTTCG.returnEmb('cat',catNum)\n",
    "        gcn_cat=catGCN(userGraph,catNode)\n",
    "        gcn_cat_emb=utils.idx_to_emb(c,gcn_cat,catPad,device)\n",
    "\n",
    "        utcGraph=C[u]\n",
    "        timeNode=DTTCG.returnEmb('time',catNum+48)\n",
    "        gcn_time=timeGCN(utcGraph,timeNode)\n",
    "        gcn_time_emb=utils.idx_to_emb(t,gcn_time,timePad,device)\n",
    "\n",
    "        poiNode=DTTCG.returnEmb('poi',poiNum)\n",
    "        gcn_poi=disGCN(disGraph,poiNode)\n",
    "        gcn_poi_emb=utils.idx_to_emb(p,gcn_poi,poiPad,device)\n",
    "\n",
    "        last_cat=[]\n",
    "        for i in range(len(lastc)):\n",
    "            idx=lastc[i]\n",
    "            lc=gcn_cat[i][idx]\n",
    "            last_cat.append(lc)\n",
    "        lastc=torch.stack(last_cat)\n",
    "        \n",
    "        predsc,preds,loss3 = DTTCG(u, gcn_cat_emb, gcn_time_emb, gcn_poi_emb,lastc)\n",
    "        with torch.no_grad():\n",
    "            correct+=utils.topk(preds,targets,1)\n",
    "            correctc+=utils.topk(predsc,targetsc,1)\n",
    "\n",
    "        loss1 = criterion(preds, targets.long())\n",
    "        loss2 = criterionc(predsc, targetsc.long())\n",
    "        loss = loss1+loss2+loss3\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "    train_loss=loss_sum/num\n",
    "    train_acc_cat=correctc*100/len(TrainData)\n",
    "    train_acc_poi=correct*100/len(TrainData)\n",
    "\n",
    "    DTTCG.eval()\n",
    "    catGCN.eval()\n",
    "    timeGCN.eval()\n",
    "    disGCN.eval()\n",
    "    correct, correctc=0,0\n",
    "    loss_sum, num=0, len(test_loader.dataset)\n",
    "    val_loss=[]\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(test_loader):\n",
    "            p, c, t, u, targets, targetsc, lastc = [d.to(device) for d in batch]\n",
    "\n",
    "            userGraph=A[u]\n",
    "            catNode=DTTCG.returnEmb('cat',catNum)\n",
    "            gcn_cat=catGCN(userGraph,catNode)\n",
    "            gcn_cat_emb=utils.idx_to_emb(c,gcn_cat,catPad,device)\n",
    "\n",
    "            utcGraph=C[u]\n",
    "            timeNode=DTTCG.returnEmb('time',catNum+48)\n",
    "            gcn_time=timeGCN(utcGraph,timeNode)\n",
    "            gcn_time_emb=utils.idx_to_emb(t,gcn_time,timePad,device)\n",
    "\n",
    "            poiNode=DTTCG.returnEmb('poi',poiNum)\n",
    "            gcn_poi=disGCN(disGraph,poiNode)\n",
    "            gcn_poi_emb=utils.idx_to_emb(p,gcn_poi,poiPad,device)\n",
    "\n",
    "            last_cat=[]\n",
    "            for i in range(len(lastc)):\n",
    "                idx=lastc[i]\n",
    "                lc=gcn_cat[i][idx]\n",
    "                last_cat.append(lc)\n",
    "            lastc=torch.stack(last_cat)\n",
    "\n",
    "            predsc, preds , loss3= DTTCG(u, gcn_cat_emb, gcn_time_emb, gcn_poi_emb, lastc)\n",
    "            correct+=utils.topk(preds,targets,1)\n",
    "            correctc+=utils.topk(predsc,targetsc,1)\n",
    "\n",
    "            loss1 = criterion(preds, targets.long())\n",
    "            loss2 = criterionc(predsc, targetsc.long())\n",
    "            loss = loss1+loss2+loss3\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "    test_loss=loss_sum/num\n",
    "    scheduler.step()\n",
    "    test_acc_cat=correctc*100/len(ValidationData)\n",
    "    test_acc_poi=correct*100/len(ValidationData)\n",
    "\n",
    "    print(\"Epoch:{}/{}  Lr:{:.6f} Traing Loss:{:.3f} TestLoss:{:.3f} Training_Cat_Acc:{:.3f} Test_Cat_Acc:{:.3f}   Training_POI_Acc {:.3f} %  Test_POI_Acc {:.3f} %\".format(epoch + 1,\n",
    "                                                                                                            epochs,optimizer.state_dict()['param_groups'][0]['lr'],\n",
    "                                                                                                            train_loss,test_loss,\n",
    "                                                                                                            train_acc_cat,test_acc_cat,\n",
    "                                                                                                            train_acc_poi,test_acc_poi))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category=GCN+att+lastc  time=GCN+att  BPRloss   fuse(disGCN+user)+fuse(crep+trep)\n",
    "def evaluteTop(model, loader):\n",
    "    model.eval()\n",
    "    total = len(loader.sampler)\n",
    "    correct=[0,0,0,0]\n",
    "    correctc=[0,0,0,0]\n",
    "    toplist=[1,5,10,20]\n",
    "    mrr_acc=0\n",
    "    for batch in loader:\n",
    "        p, c, t, u, targets, targetsc, lastc = [d.to(device) for d in batch]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            userGraph=A[u]\n",
    "            catNode=model.returnEmb('cat',catNum)\n",
    "            gcn_cat=catGCN(userGraph,catNode)\n",
    "            gcn_cat_emb=utils.idx_to_emb(c,gcn_cat,catPad,device)\n",
    "\n",
    "            utcGraph=C[u]\n",
    "            timeNode=model.returnEmb('time',catNum+48)\n",
    "            gcn_time=timeGCN(utcGraph,timeNode)\n",
    "            gcn_time_emb=utils.idx_to_emb(t,gcn_time,timePad,device)\n",
    "\n",
    "            poiNode=model.returnEmb('poi',poiNum)\n",
    "            gcn_poi=disGCN(disGraph,poiNode)\n",
    "            gcn_poi_emb=utils.idx_to_emb(p,gcn_poi,poiPad,device)\n",
    "\n",
    "            last_cat=[]\n",
    "            for i in range(len(lastc)):\n",
    "                idx=lastc[i]\n",
    "                lc=gcn_cat[i][idx]\n",
    "                last_cat.append(lc)\n",
    "            lastc=torch.stack(last_cat)\n",
    "\n",
    "            predsc, preds , loss3= model(u, gcn_cat_emb, gcn_time_emb, gcn_poi_emb, lastc)\n",
    "\n",
    "            num=0\n",
    "            for top_k in [1,5,10,20]:\n",
    "                correctc[num] +=utils.topk(predsc,targetsc,top_k)\n",
    "                correct[num] +=utils.topk(preds,targets,top_k)\n",
    "                num+=1\n",
    "                \n",
    "            sort_pred,idx=torch.sort(preds,descending=True)\n",
    "            idx=idx.to('cpu').numpy()\n",
    "            y=targets.to('cpu').numpy()\n",
    "            for i in range(len(y)):\n",
    "                index=np.where(idx[i]==y[i])\n",
    "                mrr_acc+=1/(index[0]+1)\n",
    "    print('MRR accuracy : {} %'.format(mrr_acc*100/total))\n",
    "    for tk,i in zip(toplist,correctc):            \n",
    "        print('Top {topk} Accuracy of category rec: {acc} %'.format(topk=tk,acc=i*100 / total))\n",
    "\n",
    "    for tk,i in zip(toplist,correct):\n",
    "        print('Top {topk} Accuracy poi rec: {acc} %'.format(topk=tk,acc=i*100 / total))\n",
    "    \n",
    "#print('Test Accuracy of the model on the top1 test: {} %'.format(100 *evaluteTop(model,test_loader,1)))\n",
    "evaluteTop(DTTCG,test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdc4710465637497c3384a9a94ff34762b66d87ddbf5df8d15cf56aada0f0a09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
